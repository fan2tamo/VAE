{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Input, Activation, Add, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Convolution3D, MaxPooling3D, GlobalAveragePooling3D, Lambda, UpSampling3D, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from keras.losses import mse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(latent_dim = 100, channel = 1, frame = 3, height = 100, width = 100):\n",
    "    input_data = Input(shape=(frame, height, width, channel))\n",
    "\n",
    "    x = Convolution3D(64, (3,3,3),  kernel_initializer='he_normal', padding='same', activation=\"relu\")(input_data)\n",
    "    x = MaxPooling3D((1,2,2), padding=\"same\")(x)        \n",
    "    \n",
    "    x = Convolution3D(128, (3,3,3),  kernel_initializer='he_normal', padding='same', activation=\"relu\")(x)\n",
    "    x = MaxPooling3D((3,2,2), padding=\"same\")(x)        \n",
    "    shape = K.int_shape(x)\n",
    "    print(shape)\n",
    "    x = Flatten()(x)\n",
    "    z_mean = Dense(latent_dim, activation='linear')(x)\n",
    "    z_log_var = Dense(latent_dim, activation='linear')(x)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    return Model(input_data, [z_mean, z_log_var, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 25, 25, 128)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(channel=1, frame=3, height=100, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 3, 100, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_46 (Conv3D)              (None, 3, 100, 100,  1792        input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling3D) (None, 3, 50, 50, 64 0           conv3d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_47 (Conv3D)              (None, 3, 50, 50, 12 221312      max_pooling3d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling3D) (None, 1, 25, 25, 12 0           conv3d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 80000)        0           max_pooling3d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 100)          8000100     flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 100)          8000100     flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 100)          0           dense_36[0][0]                   \n",
      "                                                                 dense_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 16,223,304\n",
      "Trainable params: 16,223,304\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder(latent_dim = 100, channel = 1, frame = 3, height = 100, width = 100):\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(1 * 25 * 25 * 128, activation='relu')(latent_inputs)\n",
    "    x = Reshape((1, 25, 25, 128))(x)\n",
    "\n",
    "    x = UpSampling3D((3, 2, 2))(x)\n",
    "    x = Convolution3D(128, (3,3,3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling3D((1, 2, 2))(x)\n",
    "    x = Convolution3D(64, (3,3,3), activation='relu', padding='same')(x)\n",
    "    decoded = Convolution3D(1, (3,3,3), activation='relu', padding='same')(x)\n",
    "    return Model(latent_inputs, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 80000)             8080000   \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 1, 25, 25, 128)    0         \n",
      "_________________________________________________________________\n",
      "up_sampling3d_26 (UpSampling (None, 3, 50, 50, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_51 (Conv3D)           (None, 3, 50, 50, 128)    442496    \n",
      "_________________________________________________________________\n",
      "up_sampling3d_27 (UpSampling (None, 3, 100, 100, 128)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_52 (Conv3D)           (None, 3, 100, 100, 64)   221248    \n",
      "_________________________________________________________________\n",
      "conv3d_53 (Conv3D)           (None, 3, 100, 100, 1)    1729      \n",
      "=================================================================\n",
      "Total params: 8,745,473\n",
      "Trainable params: 8,745,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(z_mean, z_log_var):\n",
    "    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    \n",
    "    reconstruction_loss *= 100 * 100\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    \n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def Sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss *= 100 * 100\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tfukushima1\\appdata\\local\\continuum\\anaconda3\\envs\\techacademy\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "is_channels_first = False\n",
    "if is_channels_first:\n",
    "  buf = np.load('../ResNet/resnet3d_data_channel_first_updown_and_wipe_frame-3_stride123_gray_100x100_20191016.npz')\n",
    "\n",
    "else:\n",
    "  buf = np.load('../ResNet/resnet3d_data_channel_last_updown_and_wipe_frame-3_stride123_gray_100x100_20191016.npz')\n",
    "\n",
    "X = buf[\"X\"].astype(\"f2\")\n",
    "Y = buf[\"Y\"]\n",
    "del buf\n",
    "\n",
    "Y = keras.utils.to_categorical(Y, 2, dtype=\"f2\").astype(\"f2\")\n",
    "X_train, X_val,  Y_train,  Y_val = train_test_split(X, Y, train_size=0.8, shuffle=True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, train_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(channel=1, frame=3, height=100, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(3, 100, 100, 1))\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "va\n",
    "vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000002932C4F2C50>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-f12c8bfe7944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#lr_decay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0001 + 0.02 * np.math.pow(0.5, 1+epoch), verbose=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\tfukushima1\\appdata\\local\\continuum\\anaconda3\\envs\\techacademy\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \"\"\"\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tfukushima1\\appdata\\local\\continuum\\anaconda3\\envs\\techacademy\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    871\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         raise ValueError('Could not interpret optimizer identifier: ' +\n\u001b[1;32m--> 873\u001b[1;33m                          str(identifier))\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000002932C4F2C50>"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.00001)\n",
    "#lr_decay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0001 + 0.02 * np.math.pow(0.5, 1+epoch), verbose=True)\n",
    "vae.compile(optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, frame = 3, height = 100, width = 100, channel = 1, latent_dim = 100):\n",
    "        self.frame = frame\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channel = channel\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input = Input(shape=(self.frame, self.height, self.width, self.channel))\n",
    "        self.latent_inputs = Input(shape=(self.latent_dim,))        \n",
    "\n",
    "    def Build_Encoder(self):\n",
    "        x = Convolution3D(64, (3,3,3),  kernel_initializer='he_normal', padding='same', activation=\"relu\")(self.input)\n",
    "        x = MaxPooling3D((1,2,2), padding=\"same\")(x)        \n",
    "\n",
    "        x = Convolution3D(128, (3,3,3),  kernel_initializer='he_normal', padding='same', activation=\"relu\")(x)\n",
    "        x = MaxPooling3D((3,2,2), padding=\"same\")(x)        \n",
    "        self.shape = K.int_shape(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        z_mean = Dense(self.latent_dim, activation='linear')(x)\n",
    "        z_log_var = Dense(self.latent_dim, activation='linear')(x)\n",
    "        z = Lambda(self.Sampling, output_shape=(self.latent_dim,), name='z')([z_mean, z_log_var])\n",
    "        return Model(self.input, [z_mean, z_log_var, z])\n",
    "    \n",
    "    def Build_Decoder(self):\n",
    "        x = Dense(self.shape[1] * self.shape[2] * self.shape[3] * self.shape[4], activation='relu')(self.latent_inputs)\n",
    "        x = Reshape((self.shape[1], self.shape[2], self.shape[3], self.shape[4]))(x)\n",
    "\n",
    "        x = UpSampling3D((3, 2, 2))(x)\n",
    "        x = Convolution3D(128, (3,3,3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling3D((1, 2, 2))(x)\n",
    "        x = Convolution3D(64, (3,3,3), activation='relu', padding='same')(x)\n",
    "        decoded = Convolution3D(1, (3,3,3), activation='relu', padding='same')(x)\n",
    "        return Model(self.latent_inputs, decoded)        \n",
    "    \n",
    "    def Sampling(self, args):\n",
    "        \"\"\"\n",
    "        reparameterization trick\n",
    "        instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "        z = z_mean + sqrt(var)*eps\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean=0 and std=1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def Build(self):\n",
    "        self.encoder = self.Build_Encoder()\n",
    "        self.decoder = self.Build_Decoder()\n",
    "        z_mean, z_log_var, z = self.encoder(self.input)\n",
    "        outputs = self.decoder(z)\n",
    "        self.vae = Model(self.input, outputs)\n",
    "\n",
    "        reconstruction_loss = mse(K.flatten(self.input), K.flatten(outputs))\n",
    "\n",
    "        reconstruction_loss *= self.shape[1] * self.shape[2] * self.shape[3]\n",
    "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        self.vae.add_loss(vae_loss)\n",
    "        self.vae.compile(optimizer=\"adam\")\n",
    "        \n",
    "    def fit(self, X_train, X_test, batch_size, epoch):\n",
    "        self.vae.fit(X_train, batch_size = batch_size, epochs = epoch, validation_data=(X_test, None))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1020 17:44:35.863726 18412 deprecation.py:506] From C:\\Users\\tfukushima1\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1020 17:44:36.501116 18412 training_utils.py:1101] Output model_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_1.\n"
     ]
    }
   ],
   "source": [
    "vae.Build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tfukushima1\\appdata\\local\\continuum\\anaconda3\\envs\\techacademy\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "is_channels_first = False\n",
    "if is_channels_first:\n",
    "  buf = np.load('../ResNet/resnet3d_data_channel_first_updown_and_wipe_frame-3_stride123_gray_100x100_20191016.npz')\n",
    "\n",
    "else:\n",
    "  buf = np.load('../ResNet/resnet3d_data_channel_last_updown_and_wipe_frame-3_stride123_gray_100x100_20191016.npz')\n",
    "\n",
    "X = buf[\"X\"].astype(\"f2\")\n",
    "Y = buf[\"Y\"]\n",
    "del buf\n",
    "\n",
    "Y = keras.utils.to_categorical(Y, 2, dtype=\"f2\").astype(\"f2\")\n",
    "X_train, X_val,  Y_train,  Y_val = train_test_split(X, Y, train_size=0.8, shuffle=True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, train_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1574 samples, validate on 394 samples\n",
      "Epoch 1/2\n",
      "  30/1574 [..............................] - ETA: 1:06:23 - loss: 22736260935.8412"
     ]
    }
   ],
   "source": [
    "vae.fit(X_train, X_test, batch_size=2, epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
